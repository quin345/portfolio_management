{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b06e346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              EURUSD       SPX      GOLD\n",
      "timestamp                               \n",
      "2015-12-29 -0.004443  0.011363  0.000675\n",
      "2015-12-30  0.000851 -0.008199 -0.006714\n",
      "2015-12-31 -0.007034 -0.002425 -0.000689\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define base paths for each asset\n",
    "base_paths = {\n",
    "    'EURUSD': r'C:\\Users\\jessi\\OneDrive\\Projects\\portfolio_management\\database\\data\\raw\\tick_data\\download\\eurusd_tick_data.h5',\n",
    "    'SPX': r'C:\\Users\\jessi\\OneDrive\\Projects\\portfolio_management\\database\\data\\raw\\tick_data\\download\\usa500idxusd_tick_data.h5',\n",
    "    'GOLD': r'C:\\Users\\jessi\\OneDrive\\Projects\\portfolio_management\\database\\data\\raw\\tick_data\\download\\xauusd_tick_data.h5'\n",
    "}\n",
    "\n",
    "def load_tick_data(h5_path, symbol):\n",
    "    dfs = []\n",
    "    with pd.HDFStore(h5_path, mode='r') as store:\n",
    "        for year in ['y2015']:\n",
    "            for month in [f'm{str(m).zfill(2)}' for m in range(1, 13)]:\n",
    "                for day in [f'd{str(d).zfill(2)}' for d in range(1, 32)]:\n",
    "                    key = f'/{symbol}/{year}/{month}/{day}'\n",
    "                    if key in store.keys():\n",
    "                        df = store[key]\n",
    "                        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "                        df.set_index('timestamp', inplace=True)\n",
    "                        df['mid'] = (df['askPrice'] + df['bidPrice']) / 2\n",
    "                        dfs.append(df[['mid']])\n",
    "    return pd.concat(dfs).sort_index()\n",
    "\n",
    "# Load tick data for each asset\n",
    "eurusd_df = load_tick_data(base_paths['EURUSD'], 'eurusd')\n",
    "spx_df = load_tick_data(base_paths['SPX'], 'usa500idxusd')\n",
    "gold_df = load_tick_data(base_paths['GOLD'], 'xauusd')\n",
    "\n",
    "# Resample to daily frequency using last available price\n",
    "eurusd_daily = eurusd_df['mid'].resample('1D').last()\n",
    "spx_daily = spx_df['mid'].resample('1D').last()\n",
    "gold_daily = gold_df['mid'].resample('1D').last()\n",
    "\n",
    "# Combine into single DataFrame\n",
    "prices = pd.concat([eurusd_daily, spx_daily, gold_daily], axis=1)\n",
    "prices.columns = ['EURUSD', 'SPX', 'GOLD']\n",
    "\n",
    "# Compute daily log returns\n",
    "rets = np.log(prices).diff().dropna()\n",
    "print(rets.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "420cacd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              EURUSD       SPX      GOLD\n",
      "Date                                    \n",
      "2017-12-27 -0.001234  0.002256  0.000791\n",
      "2017-12-28  0.003611  0.005502  0.001832\n",
      "2017-12-29  0.003433  0.009383 -0.005197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# FETCH DATA FROM YFINANCE AND CALCULATE LOG RETURNS\n",
    "\n",
    "import pandas as pd, numpy as np, yfinance as yf, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tickers = ['EURUSD=X', '^GSPC', 'GC=F']\n",
    "data = yf.download(tickers, start='2015-01-01', end='2017-12-31')\n",
    "\n",
    "# Use 'Adj Close' if available, otherwise fallback to 'Close'\n",
    "if 'Adj Close' in data.columns:\n",
    "    prices = data['Adj Close']\n",
    "else:\n",
    "    prices = data['Close']\n",
    "\n",
    "prices.columns = ['EURUSD', 'SPX', 'GOLD']\n",
    "rets = np.log(prices).diff().dropna()\n",
    "print(rets.tail(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c05f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 2. FACTOR DATA\n",
    "# ================================================================\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "term = pdr.get_data_fred('T10Y2Y', start='2015-01-01', end='2017-12-31')\n",
    "dxy  = pdr.get_data_fred('DTWEXBGS', start='2015-01-01', end='2017-12-31').pct_change()\n",
    "pca = PCA(n_components=1)\n",
    "pc1 = pd.DataFrame(pca.fit_transform(rets), index=rets.index, columns=['PC1'])\n",
    "\n",
    "factors = pd.concat([term, dxy, pc1], axis=1).ffill()\n",
    "factors.columns = ['TERM', 'DXY', 'PC1']\n",
    "common_idx = rets.index.intersection(factors.index)\n",
    "rets, factors = rets.loc[common_idx], factors.loc[common_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61973444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EURUSD</th>\n",
       "      <th>SPX</th>\n",
       "      <th>GOLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>-0.011897</td>\n",
       "      <td>0.014980</td>\n",
       "      <td>-0.018447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>-0.000621</td>\n",
       "      <td>0.012711</td>\n",
       "      <td>-0.008933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>-0.005346</td>\n",
       "      <td>-0.007161</td>\n",
       "      <td>0.011563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>-0.003320</td>\n",
       "      <td>-0.001819</td>\n",
       "      <td>0.017730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-09</th>\n",
       "      <td>-0.003379</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>-0.008439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-21</th>\n",
       "      <td>0.003107</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.001984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-22</th>\n",
       "      <td>-0.001756</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>-0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>-0.001234</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.001832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>-0.005197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              EURUSD       SPX      GOLD\n",
       "2015-01-05 -0.011897  0.014980 -0.018447\n",
       "2015-01-06 -0.000621  0.012711 -0.008933\n",
       "2015-01-07 -0.005346 -0.007161  0.011563\n",
       "2015-01-08 -0.003320 -0.001819  0.017730\n",
       "2015-01-09 -0.003379  0.006270 -0.008439\n",
       "...              ...       ...       ...\n",
       "2017-12-21  0.003107  0.000947  0.001984\n",
       "2017-12-22 -0.001756  0.006371 -0.000458\n",
       "2017-12-27 -0.001234  0.002256  0.000791\n",
       "2017-12-28  0.003611  0.005502  0.001832\n",
       "2017-12-29  0.003433  0.009383 -0.005197\n",
       "\n",
       "[720 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be9885b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta Matrix B (n x k):\n",
      "             TERM       DXY       PC1\n",
      "EURUSD -0.000462 -0.338852  0.053802\n",
      "SPX    -0.000181 -0.200327  0.905926\n",
      "GOLD   -0.000382 -0.396989 -0.428842\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 3. REGRESS → BETA (Time-Series OLS per asset)\n",
    "# ================================================================\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def fit_beta(asset_ret, factor_df, window=252):\n",
    "    y = asset_ret.iloc[-window:]\n",
    "    X = sm.add_constant(factor_df.iloc[-window:])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return model.params[1:], model.params[0], model.mse_resid  # beta, alpha, sigma_e^2\n",
    "\n",
    "# Initialize beta matrix: rows = assets (n), columns = factors (k)\n",
    "B = pd.DataFrame(index=rets.columns, columns=factors.columns)\n",
    "alphas, idio_vars = {}, {}\n",
    "\n",
    "# Loop over assets\n",
    "for asset in rets.columns:\n",
    "    beta, alpha, resid_var = fit_beta(rets[asset], factors)\n",
    "    B.loc[asset] = beta  # Fill row for asset\n",
    "    alphas[asset] = alpha * 252\n",
    "    idio_vars[asset] = resid_var * 252\n",
    "\n",
    "print(\"Beta Matrix B (n x k):\\n\", B.round(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f6e5c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 4. FACTOR MODEL COVARIANCE\n",
    "# ================================================================\n",
    "Omega_f = factors.cov().values * 252  # Annualize factor covariance\n",
    "Psi = np.diag(list(idio_vars.values()))\n",
    "cov_factor = B.values @ Omega_f @ B.values.T + Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5d499d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 5. LEDOIT-WOLF + HYBRID COVARIANCE\n",
    "# ================================================================\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "def lw_cov_60d(date, returns=rets):\n",
    "    window = returns.loc[:date].tail(60)\n",
    "    return pd.DataFrame(LedoitWolf().fit(window).covariance_,\n",
    "                        index=rets.columns, columns=rets.columns)\n",
    "\n",
    "cov_lw = lw_cov_60d(rets.index[-1])\n",
    "cov_final = 0.7 * cov_lw + 0.3 * pd.DataFrame(cov_factor, index=rets.columns, columns=rets.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c11631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 6. BLACK-LITTERMAN + MV WEIGHTS (Unconstrained, Shorting Allowed)\n",
    "# ================================================================\n",
    "risk_aversion = 1\n",
    "n_assets = len(rets.columns)\n",
    "mkt_w = pd.Series([1/n_assets]*n_assets, index=rets.columns)\n",
    "pi = risk_aversion * cov_final @ mkt_w\n",
    "\n",
    "P = np.array([[1, 0, 0],   # EURUSD = 6%\n",
    "              [0, 1,  0]])  # SPX = 9%\n",
    "Q = np.array([0.05, 0.09])\n",
    "tau = 0.07\n",
    "Omega = np.diag([tau * (P[i] @ cov_final @ P[i].T) for i in range(P.shape[0])])\n",
    "\n",
    "inv_tau_S = np.linalg.inv(tau * cov_final.values.astype(float))\n",
    "bl_mu = np.linalg.inv(inv_tau_S + P.T @ np.linalg.inv(Omega) @ P) @ \\\n",
    "        (inv_tau_S @ pi.values + P.T @ np.linalg.inv(Omega) @ Q)\n",
    "bl_mu = pd.Series(bl_mu, index=rets.columns)\n",
    "\n",
    "# MV Optimization (Unconstrained)\n",
    "import cvxpy as cp\n",
    "w = cp.Variable(n_assets)\n",
    "ret = bl_mu.values @ w\n",
    "risk = cp.quad_form(w, cov_final.values)\n",
    "prob = cp.Problem(cp.Maximize(ret - risk_aversion * risk),\n",
    "                  [cp.sum(w) == 1])  # Only budget constraint\n",
    "prob.solve()\n",
    "w_opt = pd.Series(w.value.round(3), index=rets.columns)\n",
    "print(\"Optimal Weights:\\n\", w_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ad6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 7. REBALANCE ±5%\n",
    "# ================================================================\n",
    "current_w = w_opt.copy()\n",
    "def needs_rebalance(curr, target, thresh=0.05):\n",
    "    return ((curr - target).abs() > thresh * target).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309eee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 8. BACKTEST (Walk-Forward)\n",
    "# ================================================================\n",
    "dates = pd.date_range('2018-01-01', '2025-11-07', freq='B')\n",
    "nav = pd.Series(index=dates, dtype=float); nav.iloc[0] = 1.0\n",
    "current_w = pd.Series([1/n_assets]*n_assets, index=rets.columns)\n",
    "\n",
    "for i, d in enumerate(dates[1:], 1):\n",
    "    if d not in rets.index:\n",
    "        nav[d] = nav.iloc[i-1]\n",
    "        continue\n",
    "\n",
    "    # Re-estimate everything rolling\n",
    "    # (repeat steps 3–6 with .loc[:d])\n",
    "    # For brevity: assume w_new computed\n",
    "    if needs_rebalance(current_w, w_new):\n",
    "        current_w = w_new\n",
    "    daily_ret = (current_w * rets.loc[d]).sum()\n",
    "    nav[d] = nav.iloc[i-1] * (1 + daily_ret)\n",
    "\n",
    "nav = nav.ffill()\n",
    "print(f\"CAGR: {((nav[-1]/nav[0])**(252/len(nav))-1)*100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
